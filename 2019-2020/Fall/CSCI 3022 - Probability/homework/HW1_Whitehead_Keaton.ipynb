{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# Homework 1: Data Cleaning and Exploratory Data Analysis \n",
    "***\n",
    "\n",
    "**Name**:  Keaton Whitehead\n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Canvas by **MIDNIGHT on Friday September 13**. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available under the **Data** module on Canvas. To make life easier on the graders if they need to run your code, do not change the relative path names here. Instead, move the files around on your computer.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Remember that there is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do Kernel $\\rightarrow$ Restart & Run All as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) | [Problem 4](#p4) | [Problem 5](#p5) | [Problem 6](#p6)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p1'></a>\n",
    "\n",
    "### (10 points) Problem 1\n",
    "***\n",
    "\n",
    "<img style=\"float: left; width: 200px; padding: 3mm;\" src=\"https://aquarium.org/wp-content/uploads/2015/08/Seahorse-female.jpg\" alt=\"Drawing\"/>  \n",
    "Poseidon is studying seahorses. Locations in each of the Atlantic, Pacific, Indian, Artic, and Southern Oceans are chosen to catch and release seahorses. After being caught, the seahorses are monitored for 24 hours while being fed organic, free-range plankton. The amount of plankton that each seahorse eats is recorded in an app on Poseidonâ€™s phone, called Hippocampus. He collects 6 seahorses from the Arctic Ocean, 36 seahorses from the Pacific Ocean, 12 seahorses from the Indian Ocean, 6 seahorses from the Southern Ocean, and 42 seahorses from the Atlantic Ocean. \n",
    "\n",
    "Poseidon wants to get a sense for the average amount of plankton eaten by seahorses, so he uses the Hippcampus app to randomly choose 1 seahorse from the Arctic, 6 from the Pacific, 2 from the Indian Ocean, 1 from the Southern Ocean, and 7 from the Atlantic Ocean.\n",
    "\n",
    "$$ \\quad $$\n",
    "    \n",
    "**Part A:** Identify the following: \n",
    "\n",
    "- the population \n",
    "- the sample frame \n",
    "- the sample \n",
    "- the type of sample \n",
    "- the quantity of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All the seahorses\n",
    "- 102 collected seahorses from selected oceans\n",
    "- 1 seahorse from the Arctic, 6 from the Pacific, 2 from the Indian Ocean, 1 from the Southern Ocean, and 7 from the Atlantic Ocean (17 Seahorses)\n",
    "- Stratified sample\n",
    "- The amount of plankton the Seahorses have eaten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Poseidon repeats his sampling, again using the Hippocampus app. Now, he orders the data alphabetically by location and chooses every 3rd data value. \n",
    "    \n",
    "Identify the following: \n",
    "\n",
    "- the population \n",
    "- the sample frame \n",
    "- the sample \n",
    "- the type of sample \n",
    "- the quantity of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All Seahorses\n",
    "- 102 Seahorses from the slected oceans\n",
    "- the 1/3 of data points extracted (34 Seahorses selected) \n",
    "- Systematic sample\n",
    "- The amount of plankton the Seahorses have eaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p2'></a>\n",
    "\n",
    "### (20 points) Problem 2\n",
    "***\n",
    "\n",
    "A method to investigate the sensitivity of the sample mean and sample median to extreme outliers and changes in the dataset is to replace one or more elements in a given dataset by a number $y$ and investigate the effect when $y$ changes. To illustrate this, consider the following dataset:\n",
    " \n",
    "$$  4.3 \\quad 5.2 \\quad 5.0 \\quad y \\quad 3.8 \\quad 4.1 \\quad 5.5 \\quad 1.9 $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A:** Compute the sample mean and sample median for $y=1.5$. Then compute both quantities again for $y=6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"y = 1.5 -> Mean: 3.913 med = 4.2\")\n",
    "print(\"y = 6   -> Mean: 4.475 med = 4.65\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Is there a value for $y$ that would make the mean of the data equal to 6? If so, calculate the value of $y$ that makes the mean equal to 6. If not, clearly explain why not.\n",
    "    \n",
    "Is there a value for $y$ that would make the median of the data equal to 6? If so, calculate the values of $y$ that makes the median equal to 6. If not, clearly explain why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A: Yes there is a value that would make the mean of the data equal to 6, it is if y = 18.2\n",
    "\n",
    "Part B: No there is no value of y that would make the median of the data = 6. No matter what y is does not change the amount of data points necesary to move the median to 6. Since most of the data points are below 6, there has to be exactly the same amount of data points that are greater than 6, so that 6 would be the median.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Compute the sample variance and the sample standard deviation for the original dataset given in part A, with $y=6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "sum1 = 0\n",
    "y = 6\n",
    "varSum = 0\n",
    "A=[4.3,5.2,5,6,3.8,4.1,5.5,1.9]\n",
    "\n",
    "for i in A:\n",
    "    sum1 += i\n",
    "\n",
    "avg = sum1/len(A)\n",
    "#sqSum1 = math.sqrt((1/(len(A)-1))*(avg)**2)\n",
    "\n",
    "for i in A:\n",
    "    varSum += (i-avg)**2\n",
    "varSum = varSum/(len(A)-1)\n",
    "sqSum = math.sqrt(varSum)\n",
    "print(\"Variance for A: \" + str(varSum))\n",
    "print(\"Standard Deviation for A: \" + str(sqSum))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Compute the sample median for the following cases: \n",
    "- $y=5$ \n",
    "- $y=50$ \n",
    "- $y=4.36$ \n",
    "- $y \\to \\infty$ \n",
    "- $y \\to -\\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_median(y):\n",
    "    A = [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "    B = []\n",
    "    B.clear()\n",
    "    B = A\n",
    "    B.append(y)\n",
    "    B.sort()\n",
    "    return B\n",
    "def find_median2(y):\n",
    "    A = [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "    C = []\n",
    "    C.clear()\n",
    "    C = A\n",
    "    C.append(y)\n",
    "    C.sort()\n",
    "    return C\n",
    "def find_median3(y):\n",
    "    A = [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "    D = []\n",
    "    D.clear()\n",
    "    D = A\n",
    "    D.append(y)\n",
    "    D.sort()\n",
    "    return D\n",
    "def find_median4(y):\n",
    "    A = [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "    E = []\n",
    "    E.clear()\n",
    "    E = A\n",
    "    E.append(y)\n",
    "    E.sort()\n",
    "    return E\n",
    "def find_median5(y):\n",
    "    A = [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "    F = []\n",
    "    F.clear()\n",
    "    F = A\n",
    "    F.append(y)\n",
    "    F.sort()\n",
    "    return F\n",
    "\n",
    "def calc_median(x):\n",
    "    med_ind = len(x)/2\n",
    "    med_val = (x[int(med_ind)] + x[int(med_ind-1)])/2\n",
    "    return med_val\n",
    "    \n",
    "print(str(calc_median(find_median5(5))))\n",
    "print(str(calc_median(find_median5(50))))\n",
    "print(str(calc_median(find_median5(4.36))))\n",
    "print(str(calc_median(find_median5(100))))\n",
    "print(str(calc_median(find_median5(-100))))\n",
    "\n",
    "#I had to do seperate function because for some reason the B list would not clear each iteration of being called and it would keep previous appended items in the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Think about the previous parts, above, and describe in words or mathematical notation the answers to the following two questions:\n",
    "\n",
    "- By varying $y$, what is the set of all the possible values that the sample mean could take on?\n",
    "- By varying $y$, what is the set of all the possible values that the sample median could take on? Specifically, for what sets of $y$ values does the median take on its different possible values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a varying y, the sample mean can take on all real numbers\n",
    "- For a varying y, the sample median will vary between (4.1 and 5.0) exclusively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Describe in words or mathematical notation, what happens to the sample standard deviation when $y$ is varied in the following ways: \n",
    " \n",
    "- $y \\to \\infty$ \n",
    "- $y \\to \\bar{x}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The STD will increase as you move away from the average\n",
    "- The STD will decrease as you move closer to the average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a/ id='p3'></a>\n",
    "\n",
    "## (20 pts) Problem 3 \n",
    "***\n",
    "\n",
    "Let $x_1, x_2, \\ldots, x_n$ be $n$ observations of a variable of interest.  Recall that the sample mean $\\bar{x}_n$ and sample variance $s^2_n$ are given by \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\frac{1}{n}\\sum_{k=1}^n x_k \\quad \\textrm{and} \\quad s^2_n = \\frac{1}{n-1}\\sum_{k=1}^n \\left( x_k - \\bar{x}_n\\right)^2 \\qquad \\tag{Equation 1}\n",
    "$$\n",
    "\n",
    "where here the subscript $n$'s indicate the number of observations in the sample. Notice that a natural computation of the variance requires two passes over the data: one to compute the mean, and a second to subtract the mean from each observation and compute the sum of squares. It is often useful to be able to compute the variance in a single pass, inspecting each value $x_k$ only once; for example, when the data are being collected without enough storage to keep all the values, or when costs of memory access dominate those of computation. In this problem you will explore two methods for such an _online_ computation of the mean.  \n",
    "\n",
    "**Part A**: Show algebraically that the following relation holds between the mean of the first $n-1$ observations and the mean of all $n$ observations: \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$$\n",
    "\n",
    "Note that you can get an expression for $\\bar{x}_{n-1}$ by simply replacing $n$ in Equation 1 above with $n-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Write a function `my_sample_mean` that takes as its input a numpy array and returns the mean of that numpy array using the formulas from class (written above). Write another function `my_sample_var` that takes as its input a numpy array and returns the variance of that numpy array, again using the formulas from class (written above). You may **not** use any built-in sample mean or variance functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_sample_mean(x):\n",
    "    avg = 0\n",
    "    for i in x:\n",
    "        avg += i\n",
    "    avg = avg/len(x)\n",
    "    return avg\n",
    "\n",
    "def my_sample_var(y):\n",
    "    sample_var = 0\n",
    "    avg = my_sample_mean(y)\n",
    "    for i in y:\n",
    "        sample_var += (i - avg)**2\n",
    "    sample_var = sample_var/(len(y)-1)\n",
    "    return sample_var\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Use your functions from Part B to compute the sample mean and sample variance of the following array, which contains the plankton consumed by a sample of 12 seahorses.\n",
    "\n",
    "`pla = [98, 26, 83, 56, 60, 39, 81, 19, 72, 78, 94, 42]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pla = [98, 26, 83, 56, 60, 39, 81, 19, 72, 78, 94, 42]\n",
    "print(\"Sample Mean: \" + str(my_sample_mean(pla)))\n",
    "print(\"Sample Variance: \" + str(my_sample_var(pla)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Implement a third function called `update_mean` that implements the formula whose validity you proved in Part A. Note that this function will need to take as its input three things: $x_n$, $\\bar{x}_{n-1}$ and $n$. A function header is provided for you. This function may be auto-graded, so please do not change the given API - the order of inputs matters! If you change it, you might lose points.\n",
    "\n",
    "Use this function to compute the values that you get from taking the mean of the first seahorse's plankton, the first two seahorses, the first three seahorses, and so on up to all of the seahorse data points. Store your plankton means in a numpy array called `pla_means`.  Report all 12 estimates in `pla_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given API:\n",
    "def update_mean(prev_mean, xn, n):\n",
    "    # your code goes here!\n",
    "    return #the updated mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure your function complies with the given API, run this small test, where we suppose we have a mean of $\\bar{x}_n = 1$ with the first $2$ data points (`prev_mean`), and we update this with the 3rd ($n=3$) data point which is $x_3=2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert update_mean(1,2,3)==4/3, \"Warning: function seems broken.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(update_mean(1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<a/ id='p4'></a>\n",
    "\n",
    "## (25 pts) Problem 4\n",
    "*** \n",
    "Some claim that the final hours aboard the RMS Titanic were marked by \"class warfare\" in which the people with first-class tickets took all the good spots on the lifeboats; others claim that the final hours were characterized by male chivalry, in which the men valiantly gave up their positions in the boats and succumbed bravely to the depths of the Atlantic. \n",
    "\n",
    "We have the data on survival rates by class and by sex, so let's figure out whether there is evidence for these scenarios. Access the Titanic data in `titanic_data.csv` and store it in a Pandas DataFrame. The data contains information pertaining to class status (**Pclass**), survival (**Survived**), and gender (**Sex**) of passengers, among other things. Be sure to use the `titanic_data.csv` data set, *not* the `clean_titanic_data` file from the in-class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  36.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  18.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  14.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  27.0      1   \n",
       "4                           Allen, Mr. William Henry    male  63.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Consider the two claims: class warfare, and male chivalry. Suppose that class warfare occurred in the final hours aboard the Titanic.  What patterns might you expect to see in the data?  Suppose that male chivalry was widespread during the final hours instead. What patterns might you then expect to see in the data?  Explain both of these hypothesized patterns in words. Are these two hypotheses mutually exclusive or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use Pandas (see: `dropna`) methods to create a clean data set by removing any rows from the DataFrame that are missing values corresponding to **Survived**, **Pclass**, **Age**, or **Sex**. Store the clean data in a DataFrame called dfTitanic. Be sure to show any exploratory work determining if/where there are rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTitanic = df.dropna(subset = ['Survived', 'Pclass', 'Age', 'Sex'])\n",
    "print(len(dfTitanic))\n",
    "dfTitanic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Compute the fraction of survivors according to class and gender. There are 3 passenger classes and 2 sexes in the data set, so you should report all 6 possible combinations.  Then, answer 3 questions:\n",
    "* **(i)** Within each passenger class, were men or women more/less/equally likely to survive?\n",
    "* **(ii)**  Looking at only the male or only the female passengers, how is passenger class related to the category's survival rate?\n",
    "* **(iii)**  Did men in first class or women in third class have a higher survival rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surviveTotalMale = len(dfTitanic.loc[(dfTitanic[\"Survived\"] == 1) & (dfTitanic[\"Sex\"] == 'male')])\n",
    "surviveTotalFemale = len(dfTitanic.loc[(dfTitanic[\"Survived\"] == 1) & (dfTitanic[\"Sex\"] == 'female')])\n",
    "totalCountFemale1 = len(dfTitanic.loc[(dfTitanic[\"Pclass\"] == 1) & (dfTitanic[\"Sex\"] == \"female\")]) \n",
    "totalCountFemale2 = len(dfTitanic.loc[(dfTitanic[\"Pclass\"] == 2) & (dfTitanic[\"Sex\"] == \"female\")]) \n",
    "totalCountFemale3 = len(dfTitanic.loc[(dfTitanic[\"Pclass\"] == 3) & (dfTitanic[\"Sex\"] == \"female\")]) \n",
    "totalCountMale1 = len(dfTitanic.loc[(dfTitanic[\"Pclass\"] == 1) & (dfTitanic[\"Sex\"] == \"male\")]) \n",
    "totalCountMale2 = len(dfTitanic.loc[(dfTitanic[\"Pclass\"] == 2) & (dfTitanic[\"Sex\"] == \"male\")]) \n",
    "totalCountMale3 = len(dfTitanic.loc[(dfTitanic[\"Pclass\"] == 3) & (dfTitanic[\"Sex\"] == \"male\")]) \n",
    "surviveCount1 = len(dfTitanic.loc[(dfTitanic[\"Survived\"] == 1) & (dfTitanic[\"Pclass\"] == 1) & (dfTitanic[\"Sex\"] == 'male')])\n",
    "surviveCount2 = len(dfTitanic.loc[(dfTitanic[\"Survived\"] == 1) & (dfTitanic[\"Pclass\"] == 1) & (dfTitanic[\"Sex\"] == 'female')])\n",
    "surviveCount3 = len(dfTitanic.loc[(dfTitanic[\"Survived\"] == 1) & (dfTitanic[\"Pclass\"] == 2) & (dfTitanic[\"Sex\"] == 'male')])\n",
    "surviveCount4 = len(dfTitanic.loc[(dfTitanic[\"Survived\"] == 1) & (dfTitanic[\"Pclass\"] == 2) & (dfTitanic[\"Sex\"] == 'female')])\n",
    "surviveCount5 = len(dfTitanic.loc[(dfTitanic[\"Survived\"] == 1) & (dfTitanic[\"Pclass\"] == 3) & (dfTitanic[\"Sex\"] == 'male')])\n",
    "surviveCount6 = len(dfTitanic.loc[(dfTitanic[\"Survived\"] == 1) & (dfTitanic[\"Pclass\"] == 3) & (dfTitanic[\"Sex\"] == 'female')])\n",
    "\n",
    "print(\"Class: 1, Male:   \" + str(surviveCount1) + \", \" + str(round((surviveCount1/totalCountMale1)*100, 2)) + \"% of all males: \")\n",
    "print(\"Class: 1, Female: \" + str(surviveCount2) + \", \" + str(round((surviveCount2/totalCountFemal1)*100, 2)) + \"% of all females: \")\n",
    "print(\"Class: 2, Male:   \" + str(surviveCount3) + \", \" + str(round(surviveCount3/totalCountMale2)*100, 2)) + \"% of all males: \")\n",
    "print(\"Class: 2, Female: \" + str(surviveCount4) + \", \" + str(round((surviveCount4/totalCountFemale2)*100, 2)) + \"% of all females: \")\n",
    "print(\"Class: 3, Male:   \" + str(surviveCount5) + \", \" + str(round((surviveCount5/totalCountMale3)*100, 2)) + \"% of all males: \")\n",
    "print(\"Class: 3, Female: \" + str(surviveCount6) + \", \" + str(round((surviveCount6/totalCountFemale3)*100, 2)) + \"% of all females: \")\n",
    "print()\n",
    "print(\"1) Women were more likely to survive than men regardless of class\")\n",
    "print(\"2) By class overall the higher up on the class the more likely you were to survive for both males and females, Females had a higher survival rate than males regardless of class\")\n",
    "print(\"3) Women in third class had higher survival rates than first class males.\")\n",
    "\n",
    "\n",
    "dfTitanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Plot a histogram of all of the passenger ages, using the bin edges $[0,5,10,\\ldots,70,75,80]$ defined by `my_bins` below. How would you characterize the distribution of **AGE**? (By _characterize_ we mean that you should indicate whether the data are unimodal, bimodal, multimodal, symmetric, negatively skewed, positively skewed, etc.)  Be sure to label your axes and use your figure to justify your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_bins = range(0,85,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, h=plt.subplots(figsize=(12,7))\n",
    "dfTitanic.hist(column = \"Age\", ax = h, color = \"red\", edgecolor = \"white\", bins = my_bins)\n",
    "h.set_title(\"Titanic Passenger Ages\")\n",
    "h.set_ylabel(\"Number of Persons\")\n",
    "h.set_xlabel(\"Age (years)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: One might wonder how a passenger's age is related to the likelihood that they would survive the Titanic disaster. To answer this question graphically, plot two density histograms on the same set of axes, showing the distribution of the ages of passengers who survived, and the distribution of the ages of passengers who did not. \n",
    "* Use the bin edges $[0,5,10,\\ldots,70,75,80]$ for both histograms.\n",
    "* This problem is about a *ship* sinking in the *ocean*, so use **coral** and **seagreen** as the facecolors for your histogram boxes.\n",
    "* Plot both histograms on a single set of axes (there should be only one panel in the figure you create), but use Matplotlib/Pandas plotting functionality to make the faces of the histogram boxes somewhat transparent, so both histograms are visible.\n",
    "* Include a legend and label your axes.\n",
    "* Comment on the results. Does your figure suggest that some age ranges are more or less likely to have survived the disaster than other ages? Fully explain your reasoning and use your figure to justify your conclusions.\n",
    "* If you noticed some relationship between age and likelihood of survival, what is one possible explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survived = dfTitanic.loc[dfTitanic.Survived == 1]\n",
    "died = dfTitanic.loc[dfTitanic.Survived == 0]\n",
    "\n",
    "fig, h = plt.subplots(figsize = (12,7))\n",
    "survived.hist(column = \"Age\", density = True, ax = h, color = \"stealblue\", edgecolor = \"black\", bins = my_bins, alpha = 5.0, label = \"Survived\")\n",
    "died.hist(column = \"Age\", density = True, ax = h, color = \"red\", edgecolor = \"black\", bins = my_bins, alpha = 0.5, label = \"Died\")\n",
    "h.set_title(\"Titanic Passenger Mortality\")\n",
    "h.set_ylabel(\"Percentage of all People\")\n",
    "h.set_xlabel(\"Age (years)\")\n",
    "h.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F:** In Part E, we plotted two *density* histograms, showing the distributions of ages of passengers that survived or did not survive the Titanic disaster. Why would it be misleading for us to have plotted these as *frequency* histograms instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: Do the data suggest class warfare, male chivalry, or some combination of both characteristics in the final hours aboard the Titanic?  Justify your conclusion based on the computations done above, or do any other analysis that you like, but be sure to clearly justify your conclusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a/ id='p5'></a>\n",
    "\n",
    "## (25 pts) Problem 5 (monthly patterns)\n",
    "***\n",
    "\n",
    "NOAA's Physical Sciences division (https://www.esrl.noaa.gov/psd) houses an enormous amount of weather data.  Load `hw1BoulderPPT.csv` from the course page for the last 100 years of monthly precipitation data from Boulder.\n",
    "\n",
    "#### a) When the amount of precipitation was nonzero but too small to be recorded, this data set recorded `tr`.  Replace these with zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hw1BoulderPPt.csv\")\n",
    "noTr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Generate a series of 12 box plots with month as the x axis and precipitation on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### c) Atmospheric scientists love to group months seasonally, breaking the year into a Winter season including December, January, February; a Spring included March, April, and May; and so forth. Generate a series of 4 box plots with season as the x axis and precipitation on the y-axis.  How does folding March-April-May into one variable change the mean and standard deviation compared to the data for just April?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdf[\"Winter\"] = bdf[\"DEC\"] + bdf[\"JAN\"] + bdf[\"FEB\"]\n",
    "bdf[\"Spring\"] = bdf [\"MAR\"] + bdf[\"APR\"] + bdf[\"MAY\"]\n",
    "bdf[\"Summer\"] = bdf[\"JUN\"] + bdf[\"JUL\"] + bdf[\"AUG\"]\n",
    "bdf[\"Autum\"] = bdf[\"SEP\"] + bdf[\"OCT\"] + bdf[\"NOV\"]\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Create a density histogram of the September precipitation.  Classify and describe this histogram.  Find the data point associated with September, 2013, and recreate your histogram with that value in a different color or otherwise clearly marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code cell; use markdown cell after this for explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Calculute the mean and standard deviation of the September precipitation in this set.  Create a Tukey 5 number summary of the September precipitation.  What are a couple of advantages and disadvantages of these numerical summaries compared to each other on this subset of the data?  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code cell for calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean and Standard Deviation**\n",
    "\n",
    "| Advantages | Disadvantages |\n",
    "| --- | --- |\n",
    "| 1A | 1D |\n",
    "| 2A | 2D |\n",
    "\n",
    "**Tukey 5-Number**\n",
    "\n",
    "| Advantages | Disadvantages |\n",
    "| --- | --- |\n",
    "| 1A | 1D |\n",
    "| 2A | 2D |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a/ id='p6'></a>\n",
    "\n",
    "## (25 pts) Problem 6\n",
    "***\n",
    "In problem 3, we generated an interesting theoretical result and then verified how it worked on a given data set.  Sometimes it's easier to just see what happens on a variety of data than manipulate sums directly!  Consider the following 3 data sets:\n",
    "\n",
    "`A=[0,1,2,3,4,5,6,7,8,9]`\n",
    "\n",
    "`B=[0,0,0,12,7,18,47,25,0,13]`\n",
    "\n",
    "`C` is the random data set generated by using `np.random.randint(0,1000, size=100)`\n",
    "\n",
    "For each data set, perform the following computations:\n",
    "#### a) Compute and print the mean and standard deviation of the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### b) Compute and print  the mean and standard deviation of the new data set formed by subtracting the original mean from each observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### c) Compute and print  the mean and standard deviation of the new data set formed by subtracting the original mean from each observation and then dividing by the original standard deviation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Why might this result matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
